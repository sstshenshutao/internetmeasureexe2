{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "a) Read up on the FCC MBA program. In particular, understand how they measure broadband performance,\n",
    "choose samples, validate their collected data, and process/analyze the data for their annual reports. Briefly\n",
    "answer the following questions: Which measurement tests do probes perform? How to they validate their data?\n",
    "Where does the FCC get data on advertised speeds? (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data was collected from 3,192 volunteer panelists across the United\n",
    "States, the volunteer sample was covering major ISPs in the\n",
    "48 contiguous states across five broadband technologies.\n",
    "\n",
    "The probes did a hardware-based measurement, they did the following\n",
    "measurement tests: \"Download speed\", \"Upload speed\", \"Web browsing\",\n",
    "\"UDP latency\", \"UDP packet loss\", \"Voice over IP\", \"DNS resolution\",\n",
    "\"DNS failures\", \"ICMP latency\", \"ICMP packet loss\", \"UDP Latency under\n",
    "load\", \"Lightweight download speed\", and \"Lightweight upload speed\".\n",
    "\n",
    "The process for the data validation:\n",
    "panelist:\n",
    "• checked the ISP identified by running IP address test in the Whitebox.\n",
    "• detected the throughput speed accurately by flooding each panelist’s connection\n",
    "• confirmed the broadband service tier by ISP\n",
    "• compared the speed tier information to the panelist by SamKnows to ensure accurate tier validation.\n",
    "SamKnows manually:\n",
    "• Verified that the IP address with the ISP ip range.\n",
    "• removed the ISP metrics changed data during the program.\n",
    "• Identified inconsistent throughput with service tier.\n",
    "• Verified the downstream-upstream results with ISP speed tiers\n",
    "\n",
    "Advertised speed data is from ISP."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "b) Download and inspect the validated data from September/October 20182\n",
    ", which were used for the most\n",
    "recent annual MBA report (ninth report). How many measurement probes were part of the program as of\n",
    "Sep/Oct 2018 in total? How many of these probes were excluded from the analysis for the ninth annual report\n",
    "(absolute and relative number)? Visualize the remaining, valid probes on a map of the US based on the\n",
    "information about the unit profile and census blocks data (probes without geocoded data can be left out in the\n",
    "plot). Use different markers for different access technologies. Briefly describe the resulting plot in words, in\n",
    "particular regarding geographical distribution and clusters. Submit your numbers of probes (total, excluded\n",
    "absolute and relative), plotting script, map, and the description of the map. (3 points)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Solution b)\n",
    "\n",
    "The validated data from September/October 2018 is too large, so we didn't integrate the download\n",
    "into the python program.\n",
    "We can download the validated data with \"wget\" in terminal\n",
    "and the extracting of \"tar.gz\" file can be achieved by using \"tar\",\n",
    "we extracted the file into the \"csvdata\" folder.\n",
    "\n",
    "These operations can be achieved by running the bash file:\n",
    "```\n",
    "sh ./download_bash.sh\n",
    "```\n",
    "The folder structure should be like this:\n",
    "```\n",
    ".\n",
    "├── convert_xlsx_csv.py\n",
    "├── csvdata\n",
    "│   ├── curr_dlping.csv\n",
    "│   ├── curr_dns.csv\n",
    "│   ├── curr_httpget.csv\n",
    "│   ├── curr_httpgetmt6.csv\n",
    "│   ├── curr_httpgetmt.csv\n",
    "│   ├── curr_httppost.csv\n",
    "│   ├── curr_httppostmt6.csv\n",
    "│   ├── curr_httppostmt.csv\n",
    "│   ├── curr_ping6.csv\n",
    "│   ├── curr_ping.csv\n",
    "│   ├── curr_udpcloss.csv\n",
    "│   ├── curr_udpjitter.csv\n",
    "│   ├── curr_udplatency6.csv\n",
    "│   ├── curr_udplatency.csv\n",
    "│   ├── curr_ulping.csv\n",
    "│   ├── curr_webget.csv\n",
    "│   └── tmp_ids.csv\n",
    "├── csvexcl\n",
    "│   └── excluded-units-sept2018.xlsx\n",
    "├── csv_id_counter.py\n",
    "├── csvup\n",
    "│   └── Unit-Profile-sept2018.xlsx\n",
    "└── download_bash.sh\n",
    "```\n",
    "Then we can use the 'csv_id_counter.py' to count the \"unit_id\":\n",
    "```\n",
    "python csv_id_counter.py\n",
    "```\n",
    "We got the result: 5589, which means the number of distinct unit-ids in all of the csv-files is 5589.\n",
    "\n",
    "There are 2663 excluded probes in the file [excluded-units-sept2018.xlsx](https://data.fcc.gov/download/measuring-broadband-america/2019/excluded-units-sept2018.xlsx)\n",
    ", we can then run the script 'exclude_probes.py' to generate a dataset which contains the remaining, valid probes.\n",
    "```\n",
    "python exclude_probes.py\n",
    "# number of valid excluded probes: 3128\n",
    "```\n",
    "then we got the number of probes: 3128.\n",
    "However in the ninth report, the number of probes is 3192.\n",
    "\n",
    "So total: 5589, excluded: 2461 of 2663, remained: 3128.\n",
    "\n",
    "To visualize the map, we used the following dataset:[States-21basic](https://alicia.data.socrata.com/Government/States-21basic/jhnu-yfrj)\n",
    ", which integrate in the \"geojson\" folder. To generate the plots, we used\n",
    "geopandas. The output file would be inside the folder \"question_b_output\"\n",
    "after running the following python script:\n",
    "```\n",
    "python gpd_visual.py\n",
    "# output file would be inside the folder \"question_b_output\"\n",
    "```\n",
    "\n",
    "The IPBB can be integrated into DSL, so we generated two plots.\n",
    "\n",
    "Description of the map:\n",
    "\n",
    "According to the plot, the probes are mostly distributed in the east area. Besides, the south area also has some probe clusters.\n",
    "The fiber probes come only from the big cities. From the aspect of probes, the east states of USA develop network better\n",
    "than the west states except the west coast area.\n",
    "The DSL probes are widely distributed. They are everywhere, so the DSL is the most popular access\n",
    "technology in the whole country. The usage of cable has also no geographical features.\n",
    "They are around the whole country. We can also know that the probes from Hawaii are also participate in this program.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "c) Based on the unit profile data, group the probes by the following columns:\n",
    "\n",
    "• ISP\n",
    "\n",
    "• Technology\n",
    "\n",
    "• State\n",
    "\n",
    "• Census region\n",
    "\n",
    "For each group within the four columns, determine the number of probes, and the average (+ standard deviation)\n",
    "and median advertised download and upload speeds (in Mbps), respectively. Use the upper bound if the stated\n",
    "speeds are listed as an interval. Provide one CSV file for each ISP, technology, state, and census region (i.e., 4\n",
    "in total). Briefly discuss an observation for each CSV file that is interesting or surprising to you. Submit your\n",
    "analysis scripts and created CSV files. (2 points)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "d) Based on the unit profile data, plot a CDF for the advertised download and upload speeds (upper bounds)\n",
    "of each probe, with distinct curves for each access technology. Incorporate validated data from 20115\n",
    "(combine\n",
    "“CABLE” and “CABLE - BUSINESS” probes, drop empty ones), plotting them in the same figure as dashed or\n",
    "dotted lines. You can find an example (without curves for upload speeds) in h). Describe how the distributions\n",
    "for advertised speeds have changed from 2011 to 2018. Submit your scripts, plot, and discussion of the plot.\n",
    "(2 points)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}